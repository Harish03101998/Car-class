# -*- coding: utf-8 -*-
"""carsclass.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mbcPHQJgY1jZAHmEABDuTydL3PTskTRc
"""

# Importing pandas to see the data in structured form
import pandas as pd

df = pd.read_csv('cars_class.csv')

df.head()

df.shape

# dtypes is used to find the prescence of data other than numerical values
df.dtypes

# info is used to find the null values in data
df.info()

#since the data has no null values we can seperate data into feature matrix and target
X = df.iloc[:,0:-1] #Feature matrix
y = df.iloc[:,-1] #Target

y

y.nunique()

# Now we can split the data into train and test data

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

# Seaborn is used to visualize the data and to find outliers
import seaborn as sns

sns.boxplot(data = X_train)

#The data has huge outliers ,so Standard scaler is used to minimize outliers
from sklearn.preprocessing import StandardScaler

SS = StandardScaler()

X_train = SS.fit_transform(X_train)

sns.boxplot(X_train)

X_test = SS.transform(X_test)

sns.boxplot(X_test)

# From here we are going to apply different machine learning techniques to check which one suits well
from sklearn.linear_model import LogisticRegression #Since this is classifiaction data I've imported Logistic Regression

logreg = LogisticRegression()

logreg.fit(X_train, y_train)

y_pred = logreg.predict(X_test)

logreg.score(X_test, y_test)

from sklearn.metrics import f1_score

f1 = f1_score(y_test, y_pred, average = 'weighted')
f1

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred)

cm

sns.heatmap(cm, annot = True)

# In the above model we didn't get desired accuracy and f1_score, so we are moving to next model

from sklearn.tree import DecisionTreeClassifier
dtc = DecisionTreeClassifier(random_state = 0)
dtc.fit(X_train, y_train)
dtc.score(X_test, y_test)

y_pred = dtc.predict(X_test)

cm = confusion_matrix(y_test, y_pred)

cm

sns.heatmap(cm, annot = True)

f1 = f1_score (y_test, y_pred, average = 'weighted')
f1

# In Decision Tree Classifier also we didn't get the desired accuracy and f1_score , so we are moving to final model which is Support Vector Machine

"""Final Model"""

from sklearn.svm import SVC
svc = SVC(kernel = 'linear') #linear kernel is used to get good accuarcy and f1 score
svc.fit(X_train, y_train)
svc.score(X_test, y_test)

y_pred = svc.predict (X_test)

f1 = f1_score (y_test, y_pred, average = 'micro')
f1

cm = confusion_matrix (y_test, y_pred)

cm

sns.heatmap(cm, annot = True)

from sklearn.metrics import ConfusionMatrixDisplay

display = ConfusionMatrixDisplay (confusion_matrix = cm)

display.plot()

# In the above model we got descent accuracy and f1_score